{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr242j2bsoshxuUt+JeBlc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnamohanathota/GenerativeAI/blob/main/langchain/modules/L2_Memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jPHogYnstdri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Memory Module\n",
        "\n",
        "https://python.langchain.com/docs/modules/memory/\n",
        "\n",
        "By default, Chains and Agents are stateless, meaning that they treat each incoming query independently (like the underlying LLMs and chat models themselves). In some applications, like chatbots, it is essential to remember previous interactions, both in the short and long-term. The **Memory** class does exactly that.\n",
        "\n",
        "LangChain provides memory components in two forms:\n",
        "- Provides helper utilities for managing and manipulating previous chat messages\n",
        "- Provides easy ways to incorporate these utilities into chains\n"
      ],
      "metadata": {
        "id": "posHr0cltekk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install openai\n",
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65fNVT2BuXys",
        "outputId": "9fc5e87e-8d56-4424-e5cc-6b668ed5d1d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.233-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.18)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.9-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.0.6,>=0.0.5 (from langchain)\n",
            "  Downloading langsmith-0.0.5-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.11)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, openapi-schema-pydantic, marshmallow-enum, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.9 langchain-0.0.233 langsmith-0.0.5 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 openapi-schema-pydantic-1.2.4 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "_ = load_dotenv(find_dotenv()) # Read local .env files\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "GJF4IclSxcTr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatMessageHistory\n",
        "\n",
        "Lightweight wrapper which exposes convenience methods for saving **Human messages**, **AI messages**, and then fetching them all."
      ],
      "metadata": {
        "id": "1uvvpTiUy8yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ChatMessageHistory\n",
        "\n",
        "history = ChatMessageHistory();\n",
        "\n",
        "history.add_user_message(\"Hi..\")\n",
        "history.add_ai_message(\"Whats up ?\")\n",
        "\n",
        "print(history)\n",
        "print(history.messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6snDDYxoy22b",
        "outputId": "ec4c5781-8fbf-4ef8-dc11-8718df316e99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messages=[HumanMessage(content='Hi..', additional_kwargs={}, example=False), AIMessage(content='Whats up ?', additional_kwargs={}, example=False)]\n",
            "[HumanMessage(content='Hi..', additional_kwargs={}, example=False), AIMessage(content='Whats up ?', additional_kwargs={}, example=False)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConversationBufferMemory\n",
        "\n",
        "wrapper around **ChatMessageHistory** that extracts the messages in a variable."
      ],
      "metadata": {
        "id": "T6vzgWLX1uY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "print(memory)\n",
        "\n",
        "\n",
        "memory.chat_memory.add_user_message(\"Hi!\")\n",
        "memory.chat_memory.add_ai_message(\"Whats up ???\")\n",
        "\n",
        "print(memory)\n",
        "\n",
        "## {'history': 'Human: Hi!\\nAI: Whats up ???'}\n",
        "print(memory.load_memory_variables({}))\n",
        "\n",
        "print(\"------\")\n",
        "\n",
        "## Get the history as a list of messages\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "\n",
        "print(memory)\n",
        "\n",
        "memory.chat_memory.add_user_message(\"Hi!\")\n",
        "memory.chat_memory.add_ai_message(\"Whats up ???\")\n",
        "\n",
        "print(memory)\n",
        "\n",
        "## {'history': [HumanMessage(content='Hi!', additional_kwargs={}, example=False), AIMessage(content='Whats up ???', additional_kwargs={}, example=False)]}\n",
        "print(memory.load_memory_variables({}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QooP2yQk1-X0",
        "outputId": "8b860cb4-2c58-407e-c664-dced09e6c5f5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chat_memory=ChatMessageHistory(messages=[]) output_key=None input_key=None return_messages=False human_prefix='Human' ai_prefix='AI' memory_key='history'\n",
            "chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Hi!', additional_kwargs={}, example=False), AIMessage(content='Whats up ???', additional_kwargs={}, example=False)]) output_key=None input_key=None return_messages=False human_prefix='Human' ai_prefix='AI' memory_key='history'\n",
            "{'history': 'Human: Hi!\\nAI: Whats up ???'}\n",
            "------\n",
            "chat_memory=ChatMessageHistory(messages=[]) output_key=None input_key=None return_messages=True human_prefix='Human' ai_prefix='AI' memory_key='history'\n",
            "chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Hi!', additional_kwargs={}, example=False), AIMessage(content='Whats up ???', additional_kwargs={}, example=False)]) output_key=None input_key=None return_messages=True human_prefix='Human' ai_prefix='AI' memory_key='history'\n",
            "{'history': [HumanMessage(content='Hi!', additional_kwargs={}, example=False), AIMessage(content='Whats up ???', additional_kwargs={}, example=False)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using in a Chain"
      ],
      "metadata": {
        "id": "xc8oNk_c5xxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "llm = OpenAI(temperature=0.0)\n",
        "print(llm)\n",
        "\n",
        "# setting \"verbose=True\" so we can see the prompt\n",
        "conversation = ConversationChain(llm=llm, verbose=True, memory = ConversationBufferMemory())\n",
        "\n",
        "## Don't print \"conversation\" as this is having OpenAI API KEY\n",
        "\n",
        "conversation.predict(input=\"Hi there\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "pxdxi-xA53tV",
        "outputId": "cfcf17e5-5f7f-4a7e-f0fa-97229717eab3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mOpenAI\u001b[0m\n",
            "Params: {'model_name': 'text-davinci-003', 'temperature': 0.0, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Hi there! How can I help you?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"I'm doing well! Which country won more FIFA worldcups ? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "zOJUzbWB7QK7",
        "outputId": "7fefd9f5-8f6d-49a4-c0ce-3860ab003ab6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there\n",
            "AI:  Hi there! How can I help you?\n",
            "Human: I'm doing well! Which country won more FIFA worldcups ? \n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Brazil has won the most FIFA World Cups, with a total of five titles. They won in 1958, 1962, 1970, 1994, and 2002.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Who is most popular player?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "jZMegkuC85c_",
        "outputId": "7c00470b-43eb-4a62-9a97-31210eeb7465"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there\n",
            "AI:  Hi there! How can I help you?\n",
            "Human: I'm doing well! Which country won more FIFA worldcups ? \n",
            "AI:  Brazil has won the most FIFA World Cups, with a total of five titles. They won in 1958, 1962, 1970, 1994, and 2002.\n",
            "Human: Who is most popular player?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" That's a difficult question to answer, as popularity is subjective. However, some of the most popular players in the world include Lionel Messi, Cristiano Ronaldo, Neymar, and Zlatan Ibrahimovic.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Who won most awards?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "eqR-lCJq9FX7",
        "outputId": "df8cc5ff-51da-4854-d7a9-ca51f4e3e7cc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there\n",
            "AI:  Hi there! How can I help you?\n",
            "Human: I'm doing well! Which country won more FIFA worldcups ? \n",
            "AI:  Brazil has won the most FIFA World Cups, with a total of five titles. They won in 1958, 1962, 1970, 1994, and 2002.\n",
            "Human: Who is most popular player?\n",
            "AI:  That's a difficult question to answer, as popularity is subjective. However, some of the most popular players in the world include Lionel Messi, Cristiano Ronaldo, Neymar, and Zlatan Ibrahimovic.\n",
            "Human: Who won most awards?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Lionel Messi has won the most awards of any player in the history of the game, including six Ballon d'Or awards, six European Golden Shoes, and 32 La Liga titles.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(conversation.memory.chat_memory))\n",
        "print(conversation.memory.chat_memory)\n",
        "print(conversation.memory.chat_memory.messages)\n",
        "print(type(conversation.memory.chat_memory.messages))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRY5BrME-IjY",
        "outputId": "8e0fa969-645e-4c29-888e-f4a7ac475909"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain.memory.chat_message_histories.in_memory.ChatMessageHistory'>\n",
            "messages=[HumanMessage(content='Hi there', additional_kwargs={}, example=False), AIMessage(content=' Hi there! How can I help you?', additional_kwargs={}, example=False), HumanMessage(content=\"I'm doing well! Which country won more FIFA worldcups ? \", additional_kwargs={}, example=False), AIMessage(content=' Brazil has won the most FIFA World Cups, with a total of five titles. They won in 1958, 1962, 1970, 1994, and 2002.', additional_kwargs={}, example=False), HumanMessage(content='Who is most popular player?', additional_kwargs={}, example=False), AIMessage(content=\" That's a difficult question to answer, as popularity is subjective. However, some of the most popular players in the world include Lionel Messi, Cristiano Ronaldo, Neymar, and Zlatan Ibrahimovic.\", additional_kwargs={}, example=False), HumanMessage(content='Who won most awards?', additional_kwargs={}, example=False), AIMessage(content=\" Lionel Messi has won the most awards of any player in the history of the game, including six Ballon d'Or awards, six European Golden Shoes, and 32 La Liga titles.\", additional_kwargs={}, example=False)]\n",
            "[HumanMessage(content='Hi there', additional_kwargs={}, example=False), AIMessage(content=' Hi there! How can I help you?', additional_kwargs={}, example=False), HumanMessage(content=\"I'm doing well! Which country won more FIFA worldcups ? \", additional_kwargs={}, example=False), AIMessage(content=' Brazil has won the most FIFA World Cups, with a total of five titles. They won in 1958, 1962, 1970, 1994, and 2002.', additional_kwargs={}, example=False), HumanMessage(content='Who is most popular player?', additional_kwargs={}, example=False), AIMessage(content=\" That's a difficult question to answer, as popularity is subjective. However, some of the most popular players in the world include Lionel Messi, Cristiano Ronaldo, Neymar, and Zlatan Ibrahimovic.\", additional_kwargs={}, example=False), HumanMessage(content='Who won most awards?', additional_kwargs={}, example=False), AIMessage(content=\" Lionel Messi has won the most awards of any player in the history of the game, including six Ballon d'Or awards, six European Golden Shoes, and 32 La Liga titles.\", additional_kwargs={}, example=False)]\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Message History\n",
        "\n",
        "You may often have to save messages, and then load them to use again. This can be done easily by first converting the messages to normal python dictionaries, saving those (as json or something) and then loading those"
      ],
      "metadata": {
        "id": "XxCQwgIG_MnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import messages_from_dict, messages_to_dict\n",
        "\n",
        "dict = messages_to_dict(conversation.memory.chat_memory.messages)\n",
        "\n",
        "print(dict)\n",
        "print(type(dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViveezZB_P3f",
        "outputId": "7f4297b8-83b3-486a-8565-d78954145e7b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'type': 'human', 'data': {'content': 'Hi there', 'additional_kwargs': {}, 'example': False}}, {'type': 'ai', 'data': {'content': ' Hi there! How can I help you?', 'additional_kwargs': {}, 'example': False}}, {'type': 'human', 'data': {'content': \"I'm doing well! Which country won more FIFA worldcups ? \", 'additional_kwargs': {}, 'example': False}}, {'type': 'ai', 'data': {'content': ' Brazil has won the most FIFA World Cups, with a total of five titles. They won in 1958, 1962, 1970, 1994, and 2002.', 'additional_kwargs': {}, 'example': False}}, {'type': 'human', 'data': {'content': 'Who is most popular player?', 'additional_kwargs': {}, 'example': False}}, {'type': 'ai', 'data': {'content': \" That's a difficult question to answer, as popularity is subjective. However, some of the most popular players in the world include Lionel Messi, Cristiano Ronaldo, Neymar, and Zlatan Ibrahimovic.\", 'additional_kwargs': {}, 'example': False}}, {'type': 'human', 'data': {'content': 'Who won most awards?', 'additional_kwargs': {}, 'example': False}}, {'type': 'ai', 'data': {'content': \" Lionel Messi has won the most awards of any player in the history of the game, including six Ballon d'Or awards, six European Golden Shoes, and 32 La Liga titles.\", 'additional_kwargs': {}, 'example': False}}]\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_messages = messages_from_dict(dict)\n",
        "\n",
        "print(new_messages)\n",
        "print(type(new_messages))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhzbTpaDAVEM",
        "outputId": "8b998d39-e490-4158-a962-eaddb51139dc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[HumanMessage(content='Hi there', additional_kwargs={}, example=False), AIMessage(content=' Hi there! How can I help you?', additional_kwargs={}, example=False), HumanMessage(content=\"I'm doing well! Which country won more FIFA worldcups ? \", additional_kwargs={}, example=False), AIMessage(content=' Brazil has won the most FIFA World Cups, with a total of five titles. They won in 1958, 1962, 1970, 1994, and 2002.', additional_kwargs={}, example=False), HumanMessage(content='Who is most popular player?', additional_kwargs={}, example=False), AIMessage(content=\" That's a difficult question to answer, as popularity is subjective. However, some of the most popular players in the world include Lionel Messi, Cristiano Ronaldo, Neymar, and Zlatan Ibrahimovic.\", additional_kwargs={}, example=False), HumanMessage(content='Who won most awards?', additional_kwargs={}, example=False), AIMessage(content=\" Lionel Messi has won the most awards of any player in the history of the game, including six Ballon d'Or awards, six European Golden Shoes, and 32 La Liga titles.\", additional_kwargs={}, example=False)]\n",
            "<class 'list'>\n"
          ]
        }
      ]
    }
  ]
}